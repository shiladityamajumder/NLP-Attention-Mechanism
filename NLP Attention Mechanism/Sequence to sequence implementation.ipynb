{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_q0db0aWFvsX"
   },
   "source": [
    "# <font color='red'>**Sequence to sequence implementation**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9wpSlX2Fvsc",
    "outputId": "9cca7c9d-040d-4c54-cbe0-8c61a1c4b0b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading https://files.pythonhosted.org/packages/0a/04/d5e0bb9f2cef5d15616ebf68087a725c5dbdd71bd422bcfb35d709f98ce7/contractions-0.0.48-py2.py3-none-any.whl\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading https://files.pythonhosted.org/packages/d3/fe/021d7d76961b5ceb9f8d022c4138461d83beff36c3938dc424586085e559/textsearch-0.0.21-py2.py3-none-any.whl\n",
      "Collecting anyascii\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/c7/61370d9e3c349478e89a5554c1e5d9658e1e3116cc4f2528f568909ebdf1/anyascii-0.1.7-py3-none-any.whl (260kB)\n",
      "\u001b[K     |████████████████████████████████| 266kB 4.3MB/s \n",
      "\u001b[?25hCollecting pyahocorasick\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/92/b3c70b8cf2b76f7e3e8b7243d6f06f7cb3bab6ada237b1bce57604c5c519/pyahocorasick-1.4.1.tar.gz (321kB)\n",
      "\u001b[K     |████████████████████████████████| 327kB 6.1MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.1-cp36-cp36m-linux_x86_64.whl size=84341 sha256=451388d2cc4a028631e4bea9d2a3b86a8dc4ccc2737c3080cf0ae11bc93eb054\n",
      "  Stored in directory: /root/.cache/pip/wheels/e4/ab/f7/cb39270df8f6126f3dd4c33d302357167086db460968cfc80c\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: anyascii, pyahocorasick, textsearch, contractions\n",
      "Successfully installed anyascii-0.1.7 contractions-0.0.48 pyahocorasick-1.4.1 textsearch-0.0.21\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFqotKWAFvsc"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_check_encoder(), grader_check_attention(), grader_onestepdecoder() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**\n",
    "\n",
    "**Note 1:**  There are many blogs on the attention mechanisum which might be misleading you,\n",
    " so do read the references completly and after that only please check the internet.\n",
    " The best things is to read the research papers and try to implement it on your own. \n",
    "\n",
    "**Note 2:** To complete this assignment, the reference that are mentioned will be enough.\n",
    "\n",
    "**Note 3:** If you are starting this assignment, you might have completed minimum of 20 assignment.\n",
    " If  you are still not able to implement this algorithm you might have rushed in the previous assignments \n",
    "with out learning much and didn't spend your time productively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdqmWIN9Fvsd"
   },
   "source": [
    "## Task -1: Simple Encoder and Decoder\n",
    "Implement simple Encoder-Decoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1IGsxW4Fvsd"
   },
   "source": [
    "1. Download the **Italian** to **English** translation dataset from <a href=\"http://www.manythings.org/anki/ita-eng.zip\">here</a>\n",
    "\n",
    "2. You will find **ita.txt** file in that ZIP, \n",
    "you can read that data using python and preprocess that data this way only: \n",
    "<img src='https://i.imgur.com/z0j79Jf.png'>    \n",
    "    \n",
    "3. You have to implement a simple Encoder and Decoder architecture  \n",
    "\n",
    "4. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
    "\n",
    "5. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
    "\n",
    "6.  a. Check the reference notebook <br>\n",
    "    b. <a href=\"https://medium.com/analytics-vidhya/understand-sequence-to-sequence-models-in-a-more-intuitive-way-1d517d8795bb\">Resource 2</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SB__bAVRFvsd"
   },
   "source": [
    "<font color='red'>**Load the data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hRL_JXu9Fvsd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import contractions\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iy0cHP3JFvse",
    "outputId": "f821a08c-1db7-4f65-8cb6-b64331e9f75a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343814\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "warnings.filterwarnings('ignore')\n",
    "data = open('ita.txt', 'r', encoding = 'utf-8').read().split('\\n')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Q95oey8ZFvse",
    "outputId": "656badcb-99cd-4ae7-8bd5-39c4e7c5e3c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>italin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Ciao!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corri!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corra!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Correte!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Chi?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english    italin\n",
       "0     Hi.     Ciao!\n",
       "1    Run!    Corri!\n",
       "2    Run!    Corra!\n",
       "3    Run!  Correte!\n",
       "4    Who?      Chi?"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_f = []\n",
    "for i in range(100000):\n",
    "    try:\n",
    "        english, italin = data[i].split('\\t')[0:2]\n",
    "        data_f.append([english, italin])\n",
    "    except:\n",
    "        pass\n",
    "data_f = pd.DataFrame(data_f, columns = ['english', 'italin'])\n",
    "data_f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgHn_Xb-Fvse"
   },
   "source": [
    "<font color='red'>**Preprocess data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ANcSYXgyFvse"
   },
   "outputs": [],
   "source": [
    "\"\"\"Ref: https://www.geeksforgeeks.org/nlp-expand-contractions-in-txt-processing/\"\"\"\n",
    "def preprocess(txt):\n",
    "    txt = txt.lower()\n",
    "    for a, b in enumerate(txt.split()):\n",
    "        try:\n",
    "            if len(re.findall('[^\\w\\d\\ \"]', b))> 0:\n",
    "                txt = re.sub(b, contractions.fix(b), txt)    \n",
    "            txt = re.sub('[^A-Za-z0-9èìò ]+', '', txt)\n",
    "        except:\n",
    "            return np.nan\n",
    "    return txt\n",
    "\n",
    "dat_eng = data_f.english.astype('str').apply(lambda x: preprocess(x))\n",
    "dat_ita = data_f.italin.astype('str').apply(lambda x: preprocess(x))\n",
    "data_preprocessing = pd.DataFrame(data = np.array([dat_eng, dat_ita]).T, columns = ['english', 'italin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCmcAE9OFvsf"
   },
   "source": [
    "## <font color='red'>**Implement custom encoder decoder**</font>\n",
    "<font color='red'>**Encoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LeSQVcO3Fvsf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "import tensorflow as tf\n",
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "    '''\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "        super().__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "        #Initialize Embedding layer\n",
    "        self.enc_embed = Embedding(input_dim = inp_vocab_size, output_dim = embedding_size, input_length= input_length)\n",
    "        #Intialize Encoder LSTM layer\n",
    "        self.enc_lstm = LSTM(lstm_size, return_sequences = True, return_state = True)\n",
    "\n",
    "    def call(self,input_sequence,states):\n",
    "        embedding = self.enc_embed(input_sequence)\n",
    "        output_state, enc_h, enc_c = self.enc_lstm(embedding, initial_state = states)\n",
    "        return output_state, enc_h, enc_c      \n",
    "\n",
    "    def initialize_states(self,batch_size):\n",
    "        return [tf.zeros((batch_size, self.lstm_size)), tf.zeros((batch_size, self.lstm_size))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ref: https://vineethaswani2.medium.com/spelling-error-correction-7154f781354c\n",
    "![](encoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVPptqiyFvsf"
   },
   "source": [
    "<font color='orange'>**Grader function - 1**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EYjNGYQFFvsf",
    "outputId": "912db65f-b854-49b8-89c0-395a599bed71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_check_encoder():\n",
    "    '''\n",
    "        vocab-size: Unique words of the input language,\n",
    "        embedding_size: output embedding dimension for each word after embedding layer,\n",
    "        lstm_size: Number of lstm units,\n",
    "        input_length: Length of the input sentence,\n",
    "        batch_size\n",
    "    '''\n",
    "    vocab_size=10\n",
    "    embedding_size=20\n",
    "    lstm_size=32\n",
    "    input_length=10\n",
    "    batch_size=16\n",
    "    #Intialzing encoder \n",
    "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
    "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
    "    #Intializing encoder initial states\n",
    "    initial_state=encoder.initialize_states(batch_size)\n",
    "    \n",
    "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
    "    \n",
    "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
    "    return True\n",
    "print(grader_check_encoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DGDXmim-Fvsg"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
    "        super().__init__()\n",
    "        #Initialize Embedding layer\n",
    "        self.dec_embed = Embedding(input_dim = out_vocab_size, output_dim = embedding_size, input_length = input_length)\n",
    "        #Intialize Decoder LSTM layer\n",
    "        self.dec_lstm = LSTM(lstm_size, return_sequences = True, return_state = True)\n",
    "\n",
    "    def call(self,input_sequence,initial_states):\n",
    "        embedding = self.dec_embed(input_sequence)\n",
    "        output_state, dec_h, dec_c = self.dec_lstm(embedding, initial_state = initial_states)\n",
    "        return output_state, dec_h, dec_c     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ref: https://vineethaswani2.medium.com/spelling-error-correction-7154f781354c\n",
    "![](decoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7vxw-nZFvsg"
   },
   "source": [
    "<font color='orange'>**Grader function - 2**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urcrhmF4Fvsh",
    "outputId": "6714c148-9e01-464a-e7d7-943f4b97d342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_decoder():\n",
    "    '''\n",
    "        out_vocab_size: Unique words of the target language,\n",
    "        embedding_size: output embedding dimension for each word after embedding layer,\n",
    "        dec_units: Number of lstm units in decoder,\n",
    "        input_length: Length of the input sentence,\n",
    "        batch_size\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    out_vocab_size=13 \n",
    "    embedding_dim=12 \n",
    "    input_length=10\n",
    "    dec_units=16 \n",
    "    batch_size=32\n",
    "    \n",
    "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
    "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
    "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    states=[state_h,state_c]\n",
    "    decoder=Decoder(out_vocab_size, embedding_dim, dec_units,input_length )\n",
    "    output,_,_=decoder(target_sentences, states)\n",
    "    assert(output.shape==(batch_size,input_length,dec_units))\n",
    "    return True\n",
    "print(grader_decoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "J75kdbniFvsh"
   },
   "outputs": [],
   "source": [
    "class Encoder_decoder(tf.keras.Model): \n",
    "    def __init__(self,*params):\n",
    "        super().__init__()\n",
    "        #Create encoder object\n",
    "        self.encoder = Encoder(inp_vocab_size = params[0], embedding_size = params[2], lstm_size = params[3], input_length = params[4])\n",
    "        #Create decoder object\n",
    "        self.decoder = Decoder(out_vocab_size = params[1], embedding_size = params[2], lstm_size = params[3], input_length = params[5])\n",
    "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
    "        self.dense = Dense(params[1], activation='softmax')\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, params, training = True):\n",
    "\n",
    "        enc_inp, dec_inp = params[0], params[1]\n",
    "        initial_state = self.encoder.initialize_states(batch_size)\n",
    "        output_state, enc_h, enc_c = self.encoder(enc_inp, initial_state)\n",
    "        output, _, _ = self.decoder(dec_inp ,[enc_h, enc_c])\n",
    "        return self.dense(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ref: https://vineethaswani2.medium.com/spelling-error-correction-7154f781354c\n",
    "![](Encoder_decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wDo5YmkKFvsh"
   },
   "outputs": [],
   "source": [
    "data_preprocessing['english_inp'] = '<sos> '+data_preprocessing['english']\n",
    "data_preprocessing['english_out'] = data_preprocessing['english'] + ' <eos>'\n",
    "data_preprocessing['italin'] = data_preprocessing['italin'].apply(lambda x: str(x))\n",
    "data_preprocessing['italin'] = '<sos> '+data_preprocessing['italin']+' <eos>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data_preprocessing, test_size = 0.1, random_state = 0)\n",
    "train, validation = train_test_split(train, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8N3FDR0HFvsh"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer_italian = Tokenizer()\n",
    "tokenizer_italian.fit_on_texts(train['italin'].values)\n",
    "tokenizer_english = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer_english.fit_on_texts(train['english_inp'].values + train['english_out'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CpfyvpHfFvsi"
   },
   "outputs": [],
   "source": [
    "eng_vc_len = data_preprocessing['italin'].astype(str).apply(lambda x: len(x))\n",
    "ita_vc_len = data_preprocessing['english_inp'].astype(str).apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egq1--msFvsj",
    "outputId": "9d386c56-b23a-401e-a113-ebaf7757a78d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 12.0\n",
      "10 24.0\n",
      "20 26.0\n",
      "30 28.0\n",
      "40 29.0\n",
      "50 31.0\n",
      "60 32.0\n",
      "70 34.0\n",
      "80 35.0\n",
      "90 38.0\n",
      "100 112.0\n",
      "90 38.0\n",
      "91 38.0\n",
      "92 39.0\n",
      "93 39.0\n",
      "94 40.0\n",
      "95 40.0\n",
      "96 41.0\n",
      "97 42.0\n",
      "98 43.0\n",
      "99 45.0\n",
      "100 112.0\n",
      "99.1 45.0\n",
      "99.2 46.0\n",
      "99.3 46.0\n",
      "99.4 46.0\n",
      "99.5 47.0\n",
      "99.6 48.0\n",
      "99.7 48.0\n",
      "99.8 49.0\n",
      "99.9 51.00100000000384\n",
      "100 112.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,101,10):\n",
    "    print(i,np.percentile(eng_vc_len, i))\n",
    "for i in range(90,101):\n",
    "    print(i,np.percentile(eng_vc_len, i))\n",
    "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
    "    print(i,np.percentile(eng_vc_len, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJekGbwtFvsk",
    "outputId": "3f992277-938c-427a-c332-6617c5832b59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.0\n",
      "10 18.0\n",
      "20 20.0\n",
      "30 21.0\n",
      "40 22.0\n",
      "50 23.0\n",
      "60 24.0\n",
      "70 25.0\n",
      "80 25.0\n",
      "90 26.0\n",
      "100 43.0\n",
      "90 26.0\n",
      "91 26.0\n",
      "92 26.0\n",
      "93 26.0\n",
      "94 26.0\n",
      "95 27.0\n",
      "96 27.0\n",
      "97 27.0\n",
      "98 27.0\n",
      "99 28.0\n",
      "100 43.0\n",
      "99.1 28.0\n",
      "99.2 28.0\n",
      "99.3 28.0\n",
      "99.4 28.0\n",
      "99.5 28.0\n",
      "99.6 28.0\n",
      "99.7 28.0\n",
      "99.8 29.0\n",
      "99.9 29.0\n",
      "100 43.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,101,10):\n",
    "    print(i,np.percentile(ita_vc_len, i))\n",
    "for i in range(90,101):\n",
    "    print(i,np.percentile(ita_vc_len, i))\n",
    "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
    "    print(i,np.percentile(ita_vc_len, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "X67EM_uuFvsk"
   },
   "outputs": [],
   "source": [
    "eng_voc_len = 0\n",
    "set_eng = set()\n",
    "for i in data_preprocessing['english_inp'].values+data_preprocessing['english_out'].values:\n",
    "    x = len(i.split())\n",
    "    if x > eng_voc_len:\n",
    "        eng_voc_len = x\n",
    "    for j in i.split():\n",
    "        set_eng.add(j)\n",
    "set_eng_size = len(set_eng)\n",
    "\n",
    "ita_voc_len = 0\n",
    "set_ita = set()\n",
    "for i in data_preprocessing['italin']:\n",
    "    x = len(i.split())\n",
    "    if x > ita_voc_len:\n",
    "        ita_voc_len = x\n",
    "    for j in i.split():\n",
    "        set_ita.add(j)\n",
    "set_ita_size = len(set_ita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Aq3sTFyEFvsk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\"\"\"Ref: https://gist.github.com/ashishthomaschempolil/3539a83449645391328e4694b177b18a\"\"\"\n",
    "class Dataset:\n",
    "    def __init__(self, data, tokenizer_italian, tokenizer_english, ita_voc_len, eng_voc_len):\n",
    "        self.encd_inputs = data['italin'].values\n",
    "        self.decd_inputs = data['english_inp'].values\n",
    "        self.decd_outputs = data['english_out'].values\n",
    "        self.tokenizer_english = tokenizer_english\n",
    "        self.tokenizer_italian = tokenizer_italian\n",
    "        self.ita_voc_len = ita_voc_len\n",
    "        self.eng_voc_len = eng_voc_len\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encd_sequence = self.tokenizer_italian.texts_to_sequences([self.encd_inputs[i]]) # need to pass list of values\n",
    "        self.decd_input_sequence = self.tokenizer_english.texts_to_sequences([self.decd_inputs[i]])\n",
    "        self.decd_output_sequence = self.tokenizer_english.texts_to_sequences([self.decd_outputs[i]])\n",
    "\n",
    "        self.encd_sequence = pad_sequences(self.encd_sequence, maxlen=self.ita_voc_len, dtype='int32', padding='post')\n",
    "        self.decd_input_sequence = pad_sequences(self.decd_input_sequence, maxlen=self.eng_voc_len, dtype='int32', padding='post')\n",
    "        self.decd_output_sequence = pad_sequences(self.decd_output_sequence, maxlen=self.eng_voc_len, dtype='int32', padding='post')\n",
    "        return self.encd_sequence, self.decd_input_sequence, self.decd_output_sequence\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.encd_inputs)\n",
    "\n",
    "\"\"\"Ref: https://gist.github.com/ashishthomaschempolil/60277e4ca6e7541dc96ef195fd5b839e\"\"\"\n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encd_inputs))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        return tuple([[tf.convert_to_tensor(batch[0]), tf.convert_to_tensor(batch[1])], tf.convert_to_tensor(batch[2])])\n",
    "\n",
    "    def __len__(self):  \n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M3kCtJWFFvsk",
    "outputId": "2cb5be64-95ba-4609-9f20-91d952c328fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Ref: https://ppasumarthi-69210.medium.com/word-embeddings-in-keras-be6bb3092831\"\"\"\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.300d.txt', encoding = 'utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](emb_mat.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rSEX9JnJFvsk"
   },
   "outputs": [],
   "source": [
    "\"\"\"Ref: https://ppasumarthi-69210.medium.com/word-embeddings-in-keras-be6bb3092831\"\"\"\n",
    "embedding_matrix = np.zeros((eng_vocab_size, 300))\n",
    "for word, i in tokenizer_english.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(ord)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](emb_mat_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "goP6cd8WFvsk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "import os\n",
    "import datetime\n",
    "batch_size=32\n",
    "lstm_size=128\n",
    "eng_voc_len = 50\n",
    "ita_txt_len = 29\n",
    "embedding_dim = 300\n",
    "dense_units = 256\n",
    "\n",
    "tr_dat = Dataset(train, tokenizer_italian, tokenizer_english, ita_txt_len, eng_voc_len)\n",
    "te_dat  = Dataset(test, tokenizer_italian, tokenizer_english, ita_txt_len, eng_voc_len)\n",
    "val_dat  = Dataset(validation, tokenizer_italian, tokenizer_english, ita_txt_len, eng_voc_len)\n",
    "\n",
    "train_dataloader = Dataloder(tr_dat, batch_size=batch_size)\n",
    "test_dataloader = Dataloder(te_dat, batch_size=batch_size)\n",
    "val_dataloader = Dataloder(val_dat, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cckTG9HQFvsl",
    "outputId": "6adcff69-2a34-4262-9be0-b9d89327368e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "2531/2531 [==============================] - 275s 108ms/step - loss: 0.9992 - val_loss: 0.3312\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33121, saving model to ita_eng_1\n",
      "Epoch 2/35\n",
      "2531/2531 [==============================] - 273s 108ms/step - loss: 0.3164 - val_loss: 0.2709\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33121 to 0.27088, saving model to ita_eng_1\n",
      "Epoch 3/35\n",
      "2531/2531 [==============================] - 278s 110ms/step - loss: 0.2514 - val_loss: 0.2185\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.27088 to 0.21847, saving model to ita_eng_1\n",
      "Epoch 4/35\n",
      "2531/2531 [==============================] - 278s 110ms/step - loss: 0.1987 - val_loss: 0.1833\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21847 to 0.18326, saving model to ita_eng_1\n",
      "Epoch 5/35\n",
      "2531/2531 [==============================] - 278s 110ms/step - loss: 0.1594 - val_loss: 0.1531\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.18326 to 0.15313, saving model to ita_eng_1\n",
      "Epoch 6/35\n",
      "2531/2531 [==============================] - 279s 110ms/step - loss: 0.1247 - val_loss: 0.1276\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15313 to 0.12762, saving model to ita_eng_1\n",
      "Epoch 7/35\n",
      "2531/2531 [==============================] - 279s 110ms/step - loss: 0.0946 - val_loss: 0.1081\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.12762 to 0.10805, saving model to ita_eng_1\n",
      "Epoch 8/35\n",
      "2531/2531 [==============================] - 279s 110ms/step - loss: 0.0716 - val_loss: 0.0935\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.10805 to 0.09355, saving model to ita_eng_1\n",
      "Epoch 9/35\n",
      "2531/2531 [==============================] - 279s 110ms/step - loss: 0.0545 - val_loss: 0.0841\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.09355 to 0.08409, saving model to ita_eng_1\n",
      "Epoch 10/35\n",
      "2531/2531 [==============================] - 277s 110ms/step - loss: 0.0432 - val_loss: 0.0772\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.08409 to 0.07716, saving model to ita_eng_1\n",
      "Epoch 11/35\n",
      "2531/2531 [==============================] - 277s 109ms/step - loss: 0.0349 - val_loss: 0.0735\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.07716 to 0.07353, saving model to ita_eng_1\n",
      "Epoch 12/35\n",
      "2531/2531 [==============================] - 276s 109ms/step - loss: 0.0293 - val_loss: 0.0708\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.07353 to 0.07081, saving model to ita_eng_1\n",
      "Epoch 13/35\n",
      "2531/2531 [==============================] - 275s 109ms/step - loss: 0.0249 - val_loss: 0.0688\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.07081 to 0.06884, saving model to ita_eng_1\n",
      "Epoch 14/35\n",
      "2531/2531 [==============================] - 271s 107ms/step - loss: 0.0218 - val_loss: 0.0674\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.06884 to 0.06737, saving model to ita_eng_1\n",
      "Epoch 15/35\n",
      "2531/2531 [==============================] - 270s 107ms/step - loss: 0.0194 - val_loss: 0.0672\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.06737 to 0.06724, saving model to ita_eng_1\n",
      "Epoch 16/35\n",
      "2531/2531 [==============================] - 272s 108ms/step - loss: 0.0174 - val_loss: 0.0665\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.06724 to 0.06654, saving model to ita_eng_1\n",
      "Epoch 17/35\n",
      "2531/2531 [==============================] - 270s 107ms/step - loss: 0.0160 - val_loss: 0.0662\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.06654 to 0.06616, saving model to ita_eng_1\n",
      "Epoch 18/35\n",
      "2531/2531 [==============================] - 274s 108ms/step - loss: 0.0150 - val_loss: 0.0659\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.06616 to 0.06593, saving model to ita_eng_1\n",
      "Epoch 19/35\n",
      "2531/2531 [==============================] - 272s 107ms/step - loss: 0.0141 - val_loss: 0.0663\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.06593\n",
      "Epoch 20/35\n",
      "2531/2531 [==============================] - 272s 107ms/step - loss: 0.0132 - val_loss: 0.0657\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.06593 to 0.06566, saving model to ita_eng_1\n",
      "Epoch 21/35\n",
      "2531/2531 [==============================] - 271s 107ms/step - loss: 0.0126 - val_loss: 0.0666\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06566\n",
      "Epoch 22/35\n",
      "2531/2531 [==============================] - 270s 107ms/step - loss: 0.0121 - val_loss: 0.0668\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06566\n",
      "Epoch 23/35\n",
      "2531/2531 [==============================] - 272s 108ms/step - loss: 0.0117 - val_loss: 0.0669\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06566\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 24/35\n",
      "2531/2531 [==============================] - 266s 105ms/step - loss: 0.0095 - val_loss: 0.0640\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.06566 to 0.06402, saving model to ita_eng_1\n",
      "Epoch 25/35\n",
      "2531/2531 [==============================] - 266s 105ms/step - loss: 0.0080 - val_loss: 0.0637\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.06402 to 0.06373, saving model to ita_eng_1\n",
      "Epoch 26/35\n",
      "2531/2531 [==============================] - 269s 106ms/step - loss: 0.0076 - val_loss: 0.0639\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.06373\n",
      "Epoch 27/35\n",
      "2531/2531 [==============================] - 270s 107ms/step - loss: 0.0074 - val_loss: 0.0639\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.06373\n",
      "Epoch 28/35\n",
      "2531/2531 [==============================] - 271s 107ms/step - loss: 0.0073 - val_loss: 0.0642\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.06373\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 29/35\n",
      "2531/2531 [==============================] - 271s 107ms/step - loss: 0.0070 - val_loss: 0.0642\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.06373\n",
      "Epoch 30/35\n",
      "2531/2531 [==============================] - 270s 107ms/step - loss: 0.0069 - val_loss: 0.0643\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.06373\n",
      "Epoch 00030: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcf0a031e80>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Encoder_decoder(set_ita_size, set_eng_size, embedding_dim, lstm_size, ita_txt_len, eng_voc_len, dense_units)\n",
    "model.compile(optimizer = 'Adam', loss = 'sparse_categorical_crossentropy')\n",
    "log_dir=\"logs/seq2seq/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "call_back = [ModelCheckpoint('ita_eng_1', save_best_only= True, verbose = 1),TensorBoard(log_dir = log_dir, \n",
    "                              histogram_freq=1, write_graph=True), EarlyStopping(patience = 5, verbose = 1),\n",
    "                              ReduceLROnPlateau(patience = 3, verbose = 1)]\n",
    "\n",
    "model.fit(x = train_dataloader, steps_per_epoch = train_dataloader.__len__(),\n",
    "          validation_data = val_dataloader, validation_steps = val_dataloader.__len__(),\n",
    "          epochs = 35, verbose = 1, callbacks = call_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "JQbykPAtFvsl"
   },
   "outputs": [],
   "source": [
    "class pred_Encoder_decoder(tf.keras.Model): \n",
    "    def __init__(self,*params):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(inp_vocab_size = params[0], embedding_size = params[2], lstm_size = params[3], input_length = params[4])\n",
    "        self.decoder = Decoder(out_vocab_size = params[1], embedding_size = params[2], lstm_size = params[3], input_length = params[5])\n",
    "        self.dense = Dense(params[1], activation='softmax')\n",
    "    \n",
    "    def call(self, params, training = True):\n",
    "        enc_inp = params[0]\n",
    "        initial_state = self.encoder.initialize_states(1)\n",
    "        output_state, enc_h, enc_c = self.encoder(enc_inp, initial_state)\n",
    "        pred = tf.expand_dims([tokenizer_english.word_index['<sos>']], 0)\n",
    "        dec_h = enc_h\n",
    "        dec_c = enc_c\n",
    "        all_pred = []\n",
    "        for t in range(eng_voc_len):  \n",
    "            pred, dec_h,dec_c = self.decoder(pred, [dec_h, dec_c])\n",
    "            pred = self.dense(pred)\n",
    "            pred = tf.argmax(pred, axis = -1)\n",
    "            all_pred.append(pred)\n",
    "        return all_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://vineethaswani2.medium.com/spelling-error-correction-7154f781354c\n",
    "![](pred_Encoder_decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oaUaqfbgFvsl",
    "outputId": "e8bcb984-7dd4-49d1-bcc7-5e97773f208c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcf0bdb2e80>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = pred_Encoder_decoder(set_ita_size, set_eng_size, embedding_dim, lstm_size, ita_txt_len, eng_voc_len, dense_units)\n",
    "final_output.compile(optimizer = 'Adam', loss = 'sparse_categorical_crossentropy')\n",
    "final_output.load_weights('/content/ita_eng_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "jzhHzkOEFvsl"
   },
   "outputs": [],
   "source": [
    "def predict(input_sequence):\n",
    "    x = preprocess(input_sequence)\n",
    "    x = '<sos> '+x+' <eos>'\n",
    "    x = tokenizer_italian.texts_to_sequences([x])\n",
    "    x = pad_sequences(seq, maxlen=ita_txt_len, padding='post', dtype = np.int32)\n",
    "    y = final_output.predict(tf.expand_dims(seq, 0))\n",
    "    z = []\n",
    "    for i in y:\n",
    "        word = tokenizer_english.index_word[i[0][0]]\n",
    "        if word == '<eos>':\n",
    "            break\n",
    "        z.append(word)\n",
    "    return ' '.join(z)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qF9OQ5nFvsl",
    "outputId": "2daf9f00-c67a-44eb-9632-52feff0ff428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :  ha appena chiamato qualcuno\n",
      "predicted output :  somebody just called\n",
      "actual output : somebody just called\n"
     ]
    }
   ],
   "source": [
    "pr_final = train['italin'].values[0][6:-6]\n",
    "print('input : ', pr_final)\n",
    "result = predict(pr_final)\n",
    "print('predicted output : ',result)\n",
    "print('actual output :', train['english'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LGjXMMw9Fvsl",
    "outputId": "42640cf2-7275-4bad-a656-2010354bf040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :  io ero gelosa di voi\n",
      "predicted output :  i was jealous of you\n",
      "actual output : i was jealous of you\n"
     ]
    }
   ],
   "source": [
    "pr_final = train['italin'].values[1000][6:-6]\n",
    "print('input : ', pr_final)\n",
    "result = predict(pr_final)\n",
    "print('predicted output : ',result)\n",
    "print('actual output :', train['english'].values[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7JtmdGnFvsl",
    "outputId": "2d6da359-5446-461e-bbb2-9aae946dda74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu Score : 0.8391122289889017\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "initial =0\n",
    "for i in range(1000):\n",
    "    pr_final = test['italin'].values[i][6:-6]\n",
    "    con = test['english'].values[i]\n",
    "    pred = predict(pr_final)\n",
    "    initial+= sentence_bleu([con.split()], pred.split())\n",
    "print('Bleu Score : {}'.format(score/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-pmfYwyFvsm"
   },
   "source": [
    "## Task -2: Including Attention mechanisum\n",
    "\n",
    "1. Use the preprocessed data from Task-1\n",
    "\n",
    "2. You have to implement an Encoder and Decoder architecture with  \n",
    "attention as discussed in the reference notebook.\n",
    "\n",
    "    * Encoder   - with 1 layer LSTM <br>\n",
    "    * Decoder   - with 1 layer LSTM<br>\n",
    "    * attention -  (Please refer the <a href= 'https://drive.google.com/file/d/1z_bnc-3aubKawbR6q8wyI6Mh5ho2R1aZ/view?usp=sharing'>**reference notebook**</a> to know more about the attention mechanism.)\n",
    "3. In Global attention, we have 3 types of scoring functions(as discussed in the reference notebook).\n",
    " As a part of this assignment **you need to create 3 models for each scoring function**\n",
    "<img src='https://i.imgur.com/iD2jZo3.png'>\n",
    "\n",
    "    * In model 1 you need to implemnt \"dot\" score function\n",
    "    * In model 2 you need to implemnt \"general\" score function\n",
    "    * In model 3 you need to implemnt \"concat\" score function.<br>\n",
    "    \n",
    " **Please do add the markdown titles for each model so that we can have a better look at the code and verify.**\n",
    "4. It is mandatory to train the model with simple model.fit() only, Donot train the model with custom GradientTape()\n",
    "\n",
    "5. Using attention weights, you can plot the attention plots, \n",
    "please plot those for 2-3 examples. You can check about those in <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\">this</a>\n",
    "\n",
    "6. The attention layer has to be written by yourself only. \n",
    "The main objective of this assignment is to read and implement a paper on yourself so please do it yourself.  \n",
    "\n",
    "7. Please implement the class **onestepdecoder** as mentioned in the assignment instructions.\n",
    "\n",
    "8. You can use any tf.Keras highlevel API's to build and train the models. \n",
    " Check the reference notebook for better understanding.\n",
    "\n",
    "9. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
    "\n",
    "10. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
    "\n",
    "11. Resources:\n",
    "    a. Check the reference notebook\n",
    "    b. <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">Resource 1</a>\n",
    "    c. <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">Resource 2</a>\n",
    "    d. <a href=\"https://stackoverflow.com/questions/44238154/what-is-the-difference-between-luong-attention-and-bahdanau-attention#:~:text=Luong%20attention%20used%20top%20hidden,hidden%20state%20at%20time%20t.\">Resource 3</a>\n",
    "    \n",
    "    \n",
    "### <font color='red'>**Implement custom encoder decoder and attention layers**</font>\n",
    "<font color='red'>**Encoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "NAEe06UZFvsm"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "class Encoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "        self.enc_embed = Embedding(input_dim = inp_vocab_size, output_dim = embedding_size)\n",
    "        self.enc_lstm = LSTM(lstm_size, return_sequences = True, return_state = True)\n",
    "        \n",
    "    def call(self,input_sequence,states):\n",
    "        embedding = self.enc_embed(input_sequence)\n",
    "        output_state, enc_h, enc_c = self.enc_lstm(embedding, initial_state = states)\n",
    "        return output_state, enc_h, enc_c\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "        return [tf.zeros((batch_size, self.lstm_size)), tf.zeros((batch_size, self.lstm_size))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://vineethaswani2.medium.com/spelling-error-correction-7154f781354c\n",
    "![](encoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXYAA42-Fvsm"
   },
   "source": [
    "<font color='cyan'>**Grader function - 1**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKIVFzhYFvsm",
    "outputId": "5886a6d3-3280-4efc-cb5a-8df02ec79143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_check_encoder():\n",
    "    \n",
    "    '''\n",
    "        vocab-size: Unique words of the input language,\n",
    "        embedding_size: output embedding dimension for each word after embedding layer,\n",
    "        lstm_size: Number of lstm units in encoder,\n",
    "        input_length: Length of the input sentence,\n",
    "        batch_size\n",
    "    '''\n",
    "    \n",
    "    vocab_size=10\n",
    "    embedding_size=20\n",
    "    lstm_size=32\n",
    "    input_length=10\n",
    "    batch_size=16\n",
    "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
    "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
    "    initial_state=encoder.initialize_states(batch_size)\n",
    "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
    "    \n",
    "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
    "    return True\n",
    "print(grader_check_encoder())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5WYKEIuFvsm"
   },
   "source": [
    "<font color='cyan'>**Attention**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "e-NH-CIgFvsm"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "class Attention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,scoring_function, att_units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.scoring_function = scoring_function\n",
    "        if scoring_function == 'dot':\n",
    "            self.dot = Dot(axes = (1, 2))\n",
    "        elif scoring_function == 'general':\n",
    "            self.W = Dense(att_units)\n",
    "            self.dot = Dot(axes = (1, 2))\n",
    "        elif scoring_function == 'concat':\n",
    "            self.W1 = Dense(att_units)\n",
    "            self.W2 = Dense(att_units)\n",
    "            self.V = Dense(1)\n",
    "    def call(self,decoder_hidden_state,encoder_output):\n",
    "    \n",
    "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state, 1)\n",
    "        \n",
    "        if self.scoring_function == 'dot':\n",
    "            score = tf.transpose(self.dot([tf.transpose(decoder_hidden_state, (0, 2, 1)), encoder_output]), (0, 2,1))\n",
    "            \n",
    "        elif self.scoring_function == 'general':\n",
    "            mul = self.W(encoder_output)\n",
    "            score = tf.transpose(self.dot([tf.transpose(decoder_hidden_state, (0, 2, 1)), mul]), (0, 2,1))\n",
    "            \n",
    "        elif self.scoring_function == 'concat':\n",
    "            inter = self.W1(decoder_hidden_state) + self.W2(encoder_output)\n",
    "            tan = tf.nn.tanh(inter)\n",
    "            score = self.V(tan)\n",
    "        attention_weights = tf.nn.softmax(score, axis =1)\n",
    "        context_vector = attention_weights * encoder_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://vineethaswani2.medium.com/spelling-error-correction-7154f781354c\n",
    "![](Attention.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-Oz3l_bFvsm"
   },
   "source": [
    "<font color='cyan'>**Grader function - 2**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxZ-gv1nFvsn",
    "outputId": "b110727f-862b-4469-c08d-827e0e503595"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_check_attention(scoring_fun):\n",
    "    \n",
    "    ''' \n",
    "        att_units: Used in matrix multiplications for scoring functions,\n",
    "        input_length: Length of the input sentence,\n",
    "        batch_size\n",
    "    '''\n",
    "    \n",
    "    input_length=10\n",
    "    batch_size=16\n",
    "    att_units=32\n",
    "    \n",
    "    state_h=tf.random.uniform(shape=[batch_size,att_units])\n",
    "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,att_units])\n",
    "    attention=Attention(scoring_fun,att_units)\n",
    "    context_vector,attention_weights=attention(state_h,encoder_output)\n",
    "    assert(context_vector.shape==(batch_size,att_units) and attention_weights.shape==(batch_size,input_length,1))\n",
    "    return True\n",
    "print(grader_check_attention('dot'))\n",
    "print(grader_check_attention('general'))\n",
    "print(grader_check_attention('concat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sO4AUglUFvsn"
   },
   "source": [
    "<font color='red'>**OneStepDecoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "0GJ4xxdoFvsn"
   },
   "outputs": [],
   "source": [
    "class OneStepDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "        super(OneStepDecoder, self).__init__()\n",
    "        self.embed_dec = Embedding(input_dim = tar_vocab_size, output_dim = embedding_dim)\n",
    "        self.lstm = LSTM(dec_units, return_sequences = True, return_state = True)\n",
    "        self.attention = Attention(scoring_function = score_fun, att_units = att_units)\n",
    "        self.fc = Dense(tar_vocab_size)\n",
    "    \n",
    "    def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
    "        embed = self.embed_dec(input_to_decoder)\n",
    "        context_vect, attention_weights = self.attention(state_h, encoder_output)    \n",
    "        final_inp = tf.concat([tf.expand_dims(context_vect, 1), embed], axis = -1)\n",
    "        out, dec_h, dec_c = self.lstm(final_inp, [state_h, state_c])\n",
    "        out = tf.reshape(out, (-1, out.shape[2]))\n",
    "        output = self.fc(out)\n",
    "        return output, dec_h, dec_c, attention_weights, context_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://vineethaswani2.medium.com/spelling-error-correction-7154f781354c\n",
    "![](OneStepDecoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrSGSFpJFvsn"
   },
   "source": [
    "<font color='cyan'>**Grader function - 3**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PkrrxU-yFvsn",
    "outputId": "b95a51e4-cf1f-4481-ec31-48ac6d7fca6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_onestepdecoder(score_fun):\n",
    "    \n",
    "    tar_vocab_size=13 \n",
    "    embedding_dim=12 \n",
    "    input_length=10\n",
    "    dec_units=16 \n",
    "    att_units=16\n",
    "    batch_size=32\n",
    "    onestepdecoder=OneStepDecoder(tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
    "    input_to_decoder=tf.random.uniform(shape=(batch_size,1),maxval=10,minval=0,dtype=tf.int32)\n",
    "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
    "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    output,state_h,state_c,attention_weights,context_vector=onestepdecoder(input_to_decoder,encoder_output,state_h,state_c)\n",
    "    assert(output.shape==(batch_size,tar_vocab_size))\n",
    "    assert(state_h.shape==(batch_size,dec_units))\n",
    "    assert(state_c.shape==(batch_size,dec_units))\n",
    "    assert(attention_weights.shape==(batch_size,input_length,1))\n",
    "    assert(context_vector.shape==(batch_size,dec_units))\n",
    "    return True\n",
    "    \n",
    "print(grader_onestepdecoder('dot'))\n",
    "print(grader_onestepdecoder('general'))\n",
    "print(grader_onestepdecoder('concat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yvry50s4Fvsn"
   },
   "source": [
    "<font color='red'>**Decoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "F3ncAuq7Fvsn"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_length = input_length\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.one_step_decoder = OneStepDecoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        \n",
    "    def call(self, input_to_decoder, encoder_output, decoder_hidden_state, decoder_cell_state):\n",
    "        all_outputs = tf.TensorArray(dtype = tf.float32, size= input_to_decoder.shape[1])\n",
    "        \n",
    "        for timestep in range(input_to_decoder.shape[1]):\n",
    "            output, decoder_hidden_state, decoder_cell_state, _, _ = self.one_step_decoder(input_to_decoder[:, timestep:timestep+1], \n",
    "                                                                                             encoder_output, \n",
    "                                                                                             decoder_hidden_state,\n",
    "                                                                                             decoder_cell_state)\n",
    "            all_outputs = all_outputs.write(timestep, output)\n",
    "        all_outputs = tf.transpose(all_outputs.stack(), (1, 0, 2))\n",
    "        return all_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://vineethaswani2.medium.com/spelling-error-correction-7154f781354c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGbpDHwZFvso"
   },
   "source": [
    "<font color='cyan'>**Grader function - 4**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ol6cM1LBFvso",
    "outputId": "5aec5f6b-e75b-4108-dba6-90b888eddfe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_decoder(score_fun):\n",
    "    \n",
    "    '''\n",
    "        out_vocab_size: Unique words of the target language,\n",
    "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
    "        dec_units: Number of lstm units in decoder,\n",
    "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
    "        input_length: Length of the target sentence,\n",
    "        batch_size\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    out_vocab_size=13 \n",
    "    embedding_dim=12 \n",
    "    input_length=11\n",
    "    dec_units=16 \n",
    "    att_units=16\n",
    "    batch_size=32\n",
    "    \n",
    "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
    "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
    "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    \n",
    "    decoder=Decoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
    "    output=decoder(target_sentences,encoder_output, state_h, state_c)\n",
    "    assert(output.shape==(batch_size,input_length,out_vocab_size))\n",
    "    return True\n",
    "print(grader_decoder('dot'))\n",
    "print(grader_decoder('general'))\n",
    "print(grader_decoder('concat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jj14tyFzFvso"
   },
   "source": [
    "<font color='red'>**Encoder Decoder model**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "0Sqfv7UsFvso"
   },
   "outputs": [],
   "source": [
    "class encoder_decoder(tf.keras.Model):\n",
    "    def __init__(self, inp_vocab_size, out_vocab_size, embedding_dim, enc_units, dec_units, max_len_ita, max_len_eng, score_fun, att_units, batch_size):\n",
    "        super(encoder_decoder, self).__init__()\n",
    "        self.encoder = Encoder(inp_vocab_size, embedding_dim, enc_units, max_len_ita)\n",
    "        self.OneStepDecoder = OneStepDecoder(out_vocab_size, embedding_dim, max_len_eng, dec_units ,score_fun ,att_units)\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, data):\n",
    "        enc_inp, dec_inp = data[0], data[1]\n",
    "        initial_state = self.encoder.initialize_states(self.batch_size)\n",
    "        enc_output, enc_h, enc_c = self.encoder(enc_inp, initial_state)\n",
    "        all_outputs = tf.TensorArray(dtype = tf.float32, size= 50)\n",
    "        \n",
    "        dec_h = enc_h\n",
    "        dec_c = enc_c\n",
    "        for timestep in range(50):\n",
    "            output, dec_h, dec_c, _, _ = self.OneStepDecoder(dec_inp[:, timestep:timestep+1], \n",
    "                                                               enc_output, \n",
    "                                                               dec_h,\n",
    "                                                               dec_c)\n",
    "            all_outputs = all_outputs.write(timestep, output)\n",
    "        all_outputs = tf.transpose(all_outputs.stack(), (1, 0, 2))\n",
    "        return all_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://vineethaswani2.medium.com/spelling-error-correction-7154f781354c\n",
    "![](encoder_decoder_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YgT438pFvso"
   },
   "source": [
    "<font color='red'>**Custom loss function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "pbI2nEV6Fvso"
   },
   "outputs": [],
   "source": [
    "# Ref: https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4XPKLhBFvsp"
   },
   "source": [
    "<font color='red'>**Training**</font>\n",
    "* Implement dot function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ga1Aj8Y3Fvsp"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import*\n",
    "import os\n",
    "batch_size=128\n",
    "lstm_size=128\n",
    "max_len_eng = 50\n",
    "ita_txt_len = 29\n",
    "embedding_dim = 100\n",
    "att_units = 256\n",
    "\n",
    "tr_dat = Dataset(train, tokenizer_italian, tokenizer_english, ita_txt_len, max_len_eng)\n",
    "te_dat  = Dataset(test, tokenizer_italian, tokenizer_english, ita_txt_len, max_len_eng)\n",
    "val_dat  = Dataset(validation, tokenizer_italian, tokenizer_english, ita_txt_len, max_len_eng)\n",
    "\n",
    "train_dataloader = Dataloder(tr_dat, batch_size=batch_size)\n",
    "test_dataloader = Dataloder(te_dat, batch_size=batch_size)\n",
    "val_dataloader = Dataloder(val_dat, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "28ThqrD3Fvsp"
   },
   "outputs": [],
   "source": [
    "model = encoder_decoder(set_ita_size, set_eng_size, embedding_dim, lstm_size, lstm_size, \n",
    "                        ita_txt_len, max_len_eng, 'dot', att_units, batch_size)\n",
    "model.compile(optimizer = 'Adam', loss = loss_function)\n",
    "log_dir=\"logs/seq2seq/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "call_back = [ModelCheckpoint('ita_eng_2', save_best_only= True, verbose = 1), TensorBoard(log_dir = log_dir, \n",
    "                             histogram_freq=1, write_graph=True), EarlyStopping(patience = 5, verbose = 1), ReduceLROnPlateau(patience = 3, \n",
    "                                                                                                                              verbose = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zqWq9ER8Fvsp",
    "outputId": "9d86c8ad-b517-4d0f-91b2-d01b09d9ef6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "632/632 [==============================] - 170s 202ms/step - loss: 0.5416 - val_loss: 0.3954\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39538, saving model to ita_eng_2\n",
      "Epoch 2/35\n",
      "632/632 [==============================] - 115s 183ms/step - loss: 0.3848 - val_loss: 0.3417\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.39538 to 0.34175, saving model to ita_eng_2\n",
      "Epoch 3/35\n",
      "632/632 [==============================] - 114s 181ms/step - loss: 0.3314 - val_loss: 0.3047\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.34175 to 0.30474, saving model to ita_eng_2\n",
      "Epoch 4/35\n",
      "632/632 [==============================] - 114s 180ms/step - loss: 0.2943 - val_loss: 0.2750\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.30474 to 0.27497, saving model to ita_eng_2\n",
      "Epoch 5/35\n",
      "632/632 [==============================] - 114s 181ms/step - loss: 0.2613 - val_loss: 0.2449\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.27497 to 0.24493, saving model to ita_eng_2\n",
      "Epoch 6/35\n",
      "632/632 [==============================] - 115s 182ms/step - loss: 0.2302 - val_loss: 0.2198\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.24493 to 0.21983, saving model to ita_eng_2\n",
      "Epoch 7/35\n",
      "632/632 [==============================] - 116s 184ms/step - loss: 0.2031 - val_loss: 0.1998\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.21983 to 0.19979, saving model to ita_eng_2\n",
      "Epoch 8/35\n",
      "632/632 [==============================] - 116s 183ms/step - loss: 0.1806 - val_loss: 0.1834\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.19979 to 0.18336, saving model to ita_eng_2\n",
      "Epoch 9/35\n",
      "632/632 [==============================] - 115s 182ms/step - loss: 0.1617 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.18336 to 0.16776, saving model to ita_eng_2\n",
      "Epoch 10/35\n",
      "632/632 [==============================] - 114s 181ms/step - loss: 0.1428 - val_loss: 0.1536\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.16776 to 0.15365, saving model to ita_eng_2\n",
      "Epoch 11/35\n",
      "632/632 [==============================] - 114s 181ms/step - loss: 0.1257 - val_loss: 0.1406\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.15365 to 0.14063, saving model to ita_eng_2\n",
      "Epoch 12/35\n",
      "632/632 [==============================] - 114s 180ms/step - loss: 0.1097 - val_loss: 0.1287\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.14063 to 0.12873, saving model to ita_eng_2\n",
      "Epoch 13/35\n",
      "632/632 [==============================] - 114s 181ms/step - loss: 0.0952 - val_loss: 0.1175\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.12873 to 0.11752, saving model to ita_eng_2\n",
      "Epoch 14/35\n",
      "632/632 [==============================] - 114s 180ms/step - loss: 0.0821 - val_loss: 0.1085\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.11752 to 0.10854, saving model to ita_eng_2\n",
      "Epoch 15/35\n",
      "632/632 [==============================] - 114s 181ms/step - loss: 0.0709 - val_loss: 0.1008\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.10854 to 0.10083, saving model to ita_eng_2\n",
      "Epoch 16/35\n",
      "632/632 [==============================] - 115s 182ms/step - loss: 0.0615 - val_loss: 0.0945\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.10083 to 0.09452, saving model to ita_eng_2\n",
      "Epoch 17/35\n",
      "632/632 [==============================] - 116s 183ms/step - loss: 0.0528 - val_loss: 0.0896\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.09452 to 0.08957, saving model to ita_eng_2\n",
      "Epoch 18/35\n",
      "632/632 [==============================] - 116s 184ms/step - loss: 0.0460 - val_loss: 0.0843\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.08957 to 0.08427, saving model to ita_eng_2\n",
      "Epoch 19/35\n",
      "632/632 [==============================] - 115s 183ms/step - loss: 0.0407 - val_loss: 0.0808\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.08427 to 0.08080, saving model to ita_eng_2\n",
      "Epoch 20/35\n",
      "632/632 [==============================] - 114s 181ms/step - loss: 0.0357 - val_loss: 0.0781\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.08080 to 0.07811, saving model to ita_eng_2\n",
      "Epoch 21/35\n",
      "632/632 [==============================] - 115s 182ms/step - loss: 0.0317 - val_loss: 0.0756\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.07811 to 0.07558, saving model to ita_eng_2\n",
      "Epoch 22/35\n",
      "632/632 [==============================] - 115s 182ms/step - loss: 0.0284 - val_loss: 0.0737\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.07558 to 0.07367, saving model to ita_eng_2\n",
      "Epoch 23/35\n",
      "632/632 [==============================] - 115s 182ms/step - loss: 0.0255 - val_loss: 0.0729\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.07367 to 0.07287, saving model to ita_eng_2\n",
      "Epoch 24/35\n",
      "632/632 [==============================] - 115s 182ms/step - loss: 0.0231 - val_loss: 0.0704\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.07287 to 0.07036, saving model to ita_eng_2\n",
      "Epoch 25/35\n",
      "632/632 [==============================] - 115s 182ms/step - loss: 0.0209 - val_loss: 0.0701\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.07036 to 0.07013, saving model to ita_eng_2\n",
      "Epoch 26/35\n",
      "632/632 [==============================] - 115s 182ms/step - loss: 0.0193 - val_loss: 0.0699\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.07013 to 0.06993, saving model to ita_eng_2\n",
      "Epoch 27/35\n",
      "632/632 [==============================] - 115s 183ms/step - loss: 0.0177 - val_loss: 0.0688\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.06993 to 0.06882, saving model to ita_eng_2\n",
      "Epoch 28/35\n",
      "632/632 [==============================] - 115s 182ms/step - loss: 0.0166 - val_loss: 0.0685\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.06882 to 0.06851, saving model to ita_eng_2\n",
      "Epoch 29/35\n",
      "632/632 [==============================] - 115s 183ms/step - loss: 0.0153 - val_loss: 0.0681\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.06851 to 0.06808, saving model to ita_eng_2\n",
      "Epoch 30/35\n",
      "632/632 [==============================] - 115s 181ms/step - loss: 0.0143 - val_loss: 0.0681\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.06808\n",
      "Epoch 31/35\n",
      "632/632 [==============================] - 114s 181ms/step - loss: 0.0134 - val_loss: 0.0680\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.06808 to 0.06798, saving model to ita_eng_2\n",
      "Epoch 32/35\n",
      "632/632 [==============================] - 114s 181ms/step - loss: 0.0124 - val_loss: 0.0673\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.06798 to 0.06735, saving model to ita_eng_2\n",
      "Epoch 33/35\n",
      "632/632 [==============================] - 115s 181ms/step - loss: 0.0117 - val_loss: 0.0681\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.06735\n",
      "Epoch 34/35\n",
      "632/632 [==============================] - 115s 181ms/step - loss: 0.0112 - val_loss: 0.0677\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.06735\n",
      "Epoch 35/35\n",
      "632/632 [==============================] - 114s 180ms/step - loss: 0.0107 - val_loss: 0.0680\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.06735\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fce499d1860>"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = train_dataloader, steps_per_epoch = train_dataloader.__len__(), validation_data = val_dataloader,\n",
    "          validation_steps = val_dataloader.__len__(), epochs = 35, verbose = 1, callbacks = call_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "0wRz4MmHFvsp"
   },
   "outputs": [],
   "source": [
    "# Ref: https://vineethaswani2.medium.com/spelling-error-correction-7154f781354c\n",
    "class pred_Encoder_decoder(tf.keras.Model): \n",
    "    def __init__(self, inp_vocab_size, out_vocab_size, embedding_dim, enc_units, dec_units, max_len_ita, max_len_eng, score_fun, att_units):\n",
    "        super(pred_Encoder_decoder, self).__init__()\n",
    "        self.encoder = Encoder(inp_vocab_size, embedding_dim, enc_units, max_len_ita)\n",
    "        self.OneStepDecoder = OneStepDecoder(out_vocab_size, embedding_dim, max_len_eng, dec_units ,score_fun ,att_units)\n",
    "        self.batch_size = batch_size\n",
    "    def call(self, params):\n",
    "        enc_inp = params[0]\n",
    "        initial_state = self.encoder.initialize_states(1)\n",
    "        output_state, enc_h, enc_c = self.encoder(enc_inp, initial_state)\n",
    "        pred = tf.expand_dims([tokenizer_english.word_index['<sos>']], 0)\n",
    "        dec_h = enc_h\n",
    "        dec_c = enc_c\n",
    "        all_pred = []\n",
    "        all_attention = []\n",
    "        for t in range(50):  \n",
    "            pred, dec_h,dec_c, attention, _ = self.OneStepDecoder(pred, output_state, dec_h, dec_c)\n",
    "            pred = tf.argmax(pred, axis = -1)\n",
    "            all_pred.append(pred)\n",
    "            pred = tf.expand_dims(pred, 0)\n",
    "            all_attention.append(attention)\n",
    "        return all_pred, all_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgdtSOg_Fvsp",
    "outputId": "687ecabe-16bd-42a0-cace-0ad17d09787e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcdc3c59320>"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = pred_Encoder_decoder(set_ita_size, set_eng_size, embedding_dim, lstm_size, lstm_size, ita_txt_len, max_len_eng, 'dot', att_units)\n",
    "final_output.compile(optimizer = 'Adam', loss = loss_function)\n",
    "final_output.load_weights('/content/ita_eng_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFWXBgO-Fvsp"
   },
   "source": [
    "## <font color='red'>**Inference**</font>\n",
    "\n",
    "<font color='red'>**Plot attention weights**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "2XSr-pDOFvsq"
   },
   "outputs": [],
   "source": [
    "# Ref: https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='YlOrRd')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbcw3tvdFvsq"
   },
   "source": [
    "<font color='red'>**Predict the sentence translation**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "mbjn_WMUFvsq"
   },
   "outputs": [],
   "source": [
    "def predict(input_sequence):\n",
    "    x = preprocess(input_sequence)\n",
    "    x = '<sos> '+x+' <eos>'\n",
    "    x = tokenizer_italian.texts_to_sequences([x])\n",
    "    x = pad_sequences(seq, maxlen=ita_txt_len, padding='post', dtype = np.int32)\n",
    "    y = final_output.predict(tf.expand_dims(seq, 0))\n",
    "    z = []\n",
    "    for i in y:\n",
    "        word = tokenizer_english.index_word[i[0][0]]\n",
    "        if word == '<eos>':\n",
    "            break\n",
    "        z.append(word)\n",
    "    return ' '.join(z) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "id": "qiraS_eaFvsq",
    "outputId": "4170e1fc-d306-4bb7-b0f9-9f09ebe2918c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :  ha appena chiamato qualcuno\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted output :  she just called me\n",
      "actual output : somebody just called\n"
     ]
    }
   ],
   "source": [
    "pr_final = train['italin'].values[0][6:-6]\n",
    "print('input : ', pr_final)\n",
    "result, attention_plot = predict(pr_final)\n",
    "attention_plot = attention_plot[:len(result.split(' ')), :len(pr_final.split(' '))]\n",
    "plot_attention(attention_plot, pr_final.split(' '), result.split(' '))\n",
    "print('predicted output : ',result)\n",
    "print('actual output :', train['english'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "id": "Go_GDLlwFvsq",
    "outputId": "b18b5c22-45bb-4619-80b9-bfc3e700bae7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :  io ero gelosa di voi\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted output :  i was jealous of you\n",
      "actual output : i was jealous of you\n"
     ]
    }
   ],
   "source": [
    "pr_final = train['italin'].values[1000][6:-6]\n",
    "print('input : ', pr_final)\n",
    "result, attention_plot = predict(pr_final)\n",
    "attention_plot = attention_plot[:len(result.split(' ')), :len(pr_final.split(' '))]\n",
    "plot_attention(attention_plot, pr_final.split(' '), result.split(' '))\n",
    "print('predicted output : ',result)\n",
    "print('actual output :', train['english'].values[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqN9mB57Fvsq"
   },
   "source": [
    "#### <font color='magenta'>**Calculate BLEU score**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q34EI-mzFvsq",
    "outputId": "89275938-4bbb-47bf-d9e0-0163ef91b034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu Score : 0.8262435337297614\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "initial =0\n",
    "for i in range(1000):\n",
    "    pr_final = test['italin'].values[i][6:-6]\n",
    "    con = test['english'].values[i]\n",
    "    pred = predict(pr_final)\n",
    "    initial+= sentence_bleu([con.split()], pred.split())\n",
    "print('Bleu Score : {}'.format(score/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biPWLA3pFvsq"
   },
   "source": [
    "<font color='red'>**Repeat the same steps for General scoring function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "8LzmkGc2Fvsr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import*\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "batch_size=128\n",
    "lstm_size=256\n",
    "embedding_dim = 100\n",
    "\n",
    "tr_dat = Dataset(train, tokenizer_italian, tokenizer_english, ita_txt_len, max_len_eng)\n",
    "te_dat  = Dataset(test, tokenizer_italian, tokenizer_english, ita_txt_len, max_len_eng)\n",
    "val_dat  = Dataset(validation, tokenizer_italian, tokenizer_english, ita_txt_len, max_len_eng)\n",
    "\n",
    "train_dataloader = Dataloder(tr_dat, batch_size=batch_size)\n",
    "test_dataloader = Dataloder(te_dat, batch_size=batch_size)\n",
    "val_dataloader = Dataloder(val_dat, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "TJL82VDlFvsr"
   },
   "outputs": [],
   "source": [
    "model = encoder_decoder(set_ita_size, set_eng_size, embedding_dim, lstm_size, \n",
    "                        lstm_size, ita_txt_len, max_len_eng, 'general', att_units, batch_size)\n",
    "model.compile(optimizer = 'Adam', loss = loss_function)\n",
    "log_dir=\"logs/seq2seq/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") call_back = [ModelCheckpoint('ita_eng_3', save_best_only= True, verbose = 1),\n",
    "             TensorBoard(log_dir = log_dir, histogram_freq=1, write_graph=True), EarlyStopping(patience = 5, verbose = 1),\n",
    "             ReduceLROnPlateau(patience = 3, verbose = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDjJdErLFvsr",
    "outputId": "eac5c884-b0d4-42e7-87dd-6faa3d9a1578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "632/632 [==============================] - 212s 262ms/step - loss: 0.5123 - val_loss: 0.3987\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39868, saving model to ita_eng_3\n",
      "Epoch 2/35\n",
      "632/632 [==============================] - 148s 235ms/step - loss: 0.3832 - val_loss: 0.3175\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.39868 to 0.31746, saving model to ita_eng_3\n",
      "Epoch 3/35\n",
      "632/632 [==============================] - 149s 236ms/step - loss: 0.3014 - val_loss: 0.2587\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.31746 to 0.25873, saving model to ita_eng_3\n",
      "Epoch 4/35\n",
      "632/632 [==============================] - 148s 235ms/step - loss: 0.2429 - val_loss: 0.2157\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.25873 to 0.21567, saving model to ita_eng_3\n",
      "Epoch 5/35\n",
      "632/632 [==============================] - 149s 235ms/step - loss: 0.1979 - val_loss: 0.1817\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21567 to 0.18166, saving model to ita_eng_3\n",
      "Epoch 6/35\n",
      "632/632 [==============================] - 148s 234ms/step - loss: 0.1597 - val_loss: 0.1512\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.18166 to 0.15124, saving model to ita_eng_3\n",
      "Epoch 7/35\n",
      "632/632 [==============================] - 149s 236ms/step - loss: 0.1263 - val_loss: 0.1283\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.15124 to 0.12835, saving model to ita_eng_3\n",
      "Epoch 8/35\n",
      "632/632 [==============================] - 149s 236ms/step - loss: 0.0979 - val_loss: 0.1076\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.12835 to 0.10761, saving model to ita_eng_3\n",
      "Epoch 9/35\n",
      "632/632 [==============================] - 151s 238ms/step - loss: 0.0748 - val_loss: 0.0937\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.10761 to 0.09371, saving model to ita_eng_3\n",
      "Epoch 10/35\n",
      "632/632 [==============================] - 150s 238ms/step - loss: 0.0581 - val_loss: 0.0831\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09371 to 0.08306, saving model to ita_eng_3\n",
      "Epoch 11/35\n",
      "632/632 [==============================] - 150s 238ms/step - loss: 0.0454 - val_loss: 0.0758\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.08306 to 0.07577, saving model to ita_eng_3\n",
      "Epoch 12/35\n",
      "632/632 [==============================] - 150s 237ms/step - loss: 0.0358 - val_loss: 0.0706\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.07577 to 0.07058, saving model to ita_eng_3\n",
      "Epoch 13/35\n",
      "632/632 [==============================] - 151s 239ms/step - loss: 0.0293 - val_loss: 0.0669\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.07058 to 0.06689, saving model to ita_eng_3\n",
      "Epoch 14/35\n",
      "632/632 [==============================] - 151s 238ms/step - loss: 0.0245 - val_loss: 0.0643\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.06689 to 0.06434, saving model to ita_eng_3\n",
      "Epoch 15/35\n",
      "632/632 [==============================] - 151s 238ms/step - loss: 0.0205 - val_loss: 0.0633\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.06434 to 0.06329, saving model to ita_eng_3\n",
      "Epoch 16/35\n",
      "632/632 [==============================] - 151s 238ms/step - loss: 0.0175 - val_loss: 0.0617\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.06329 to 0.06170, saving model to ita_eng_3\n",
      "Epoch 17/35\n",
      "632/632 [==============================] - 151s 239ms/step - loss: 0.0156 - val_loss: 0.0611\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.06170 to 0.06109, saving model to ita_eng_3\n",
      "Epoch 18/35\n",
      "632/632 [==============================] - 151s 239ms/step - loss: 0.0139 - val_loss: 0.0617\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.06109\n",
      "Epoch 19/35\n",
      "632/632 [==============================] - 151s 239ms/step - loss: 0.0126 - val_loss: 0.0605\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.06109 to 0.06052, saving model to ita_eng_3\n",
      "Epoch 20/35\n",
      "632/632 [==============================] - 151s 238ms/step - loss: 0.0114 - val_loss: 0.0602\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.06052 to 0.06024, saving model to ita_eng_3\n",
      "Epoch 21/35\n",
      "632/632 [==============================] - 151s 239ms/step - loss: 0.0104 - val_loss: 0.0608\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06024\n",
      "Epoch 22/35\n",
      "632/632 [==============================] - 151s 239ms/step - loss: 0.0101 - val_loss: 0.0600\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.06024 to 0.06004, saving model to ita_eng_3\n",
      "Epoch 23/35\n",
      "632/632 [==============================] - 151s 239ms/step - loss: 0.0092 - val_loss: 0.0608\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06004\n",
      "Epoch 24/35\n",
      "632/632 [==============================] - 151s 238ms/step - loss: 0.0088 - val_loss: 0.0619\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.06004\n",
      "Epoch 25/35\n",
      "632/632 [==============================] - 151s 239ms/step - loss: 0.0085 - val_loss: 0.0613\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06004\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 26/35\n",
      "632/632 [==============================] - 151s 239ms/step - loss: 0.0066 - val_loss: 0.0589\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.06004 to 0.05885, saving model to ita_eng_3\n",
      "Epoch 27/35\n",
      "632/632 [==============================] - 151s 239ms/step - loss: 0.0053 - val_loss: 0.0589\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.05885\n",
      "Epoch 28/35\n",
      "632/632 [==============================] - 151s 238ms/step - loss: 0.0050 - val_loss: 0.0590\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.05885\n",
      "Epoch 29/35\n",
      "632/632 [==============================] - 151s 238ms/step - loss: 0.0048 - val_loss: 0.0592\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.05885\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 30/35\n",
      "632/632 [==============================] - 151s 239ms/step - loss: 0.0046 - val_loss: 0.0592\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.05885\n",
      "Epoch 31/35\n",
      "632/632 [==============================] - 151s 239ms/step - loss: 0.0045 - val_loss: 0.0592\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.05885\n",
      "Epoch 00031: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcdb75fbd68>"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = train_dataloader, steps_per_epoch = train_dataloader.__len__(), validation_data = val_dataloader,\n",
    "          validation_steps = val_dataloader.__len__(), epochs = 35, verbose = 1, callbacks = call_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nv_3yN0wFvsr",
    "outputId": "510d139f-122a-4feb-8284-1c3b876cc5c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcdb761c198>"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = pred_Encoder_decoder(set_ita_size, set_eng_size, embedding_dim, lstm_size, lstm_size, ita_txt_len, max_len_eng, 'general', att_units)\n",
    "final_output.compile(optimizer = 'Adam', loss = loss_function)\n",
    "final_output.load_weights('/content/ita_eng_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "id": "UoSULVdCFvsr",
    "outputId": "a3c955f8-9e84-4420-c64d-1e1d791c766f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :  ha appena chiamato qualcuno\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output :  somebody just called\n"
     ]
    }
   ],
   "source": [
    "pr_final = train['italin'].values[0][6:-6]\n",
    "print('input : ', pr_final)\n",
    "result = predict(pr_final)\n",
    "print('predicted output : ',result)\n",
    "print('actual output :', train['english'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 774
    },
    "id": "PnaILl4IFvsr",
    "outputId": "1f3caaa8-47b6-47dc-e0b7-67853a148305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :  io ero gelosa di voi\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output :  i was jealous of you\n"
     ]
    }
   ],
   "source": [
    "pr_final = train['italin'].values[1000][6:-6]\n",
    "print('input : ', pr_final)\n",
    "result = predict(pr_final)\n",
    "print('predicted output : ',result)\n",
    "print('actual output :', train['english'].values[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3V_bN7OFvsr",
    "outputId": "83f00d0d-2d1f-42b4-ef02-a56201d43419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu Score : 0.8442320971046736\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "initial =0\n",
    "for i in range(1000):\n",
    "    pr_final = test['italin'].values[i][6:-6]\n",
    "    con = test['english'].values[i]\n",
    "    pred = predict(pr_final)\n",
    "    initial+= sentence_bleu([con.split()], pred.split())\n",
    "print('Bleu Score : {}'.format(score/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlSkE0skFvss"
   },
   "source": [
    "<font color='red'>**Repeat the same steps for Concat scoring function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "NQJlHFO8Fvss"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import*\n",
    "import os\n",
    "batch_size=64\n",
    "lstm_size=128\n",
    "embedding_dim = 100\n",
    "\n",
    "tr_dat = Dataset(train, tokenizer_italian, tokenizer_english, ita_txt_len, max_len_eng)\n",
    "te_dat  = Dataset(test, tokenizer_italian, tokenizer_english, ita_txt_len, max_len_eng)\n",
    "val_dat  = Dataset(validation, tokenizer_italian, tokenizer_english, ita_txt_len, max_len_eng)\n",
    "\n",
    "train_dataloader = Dataloder(tr_dat, batch_size=batch_size)\n",
    "test_dataloader = Dataloder(te_dat, batch_size=batch_size)\n",
    "val_dataloader = Dataloder(val_dat, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "_Tovrfs3Fvss"
   },
   "outputs": [],
   "source": [
    "model = encoder_decoder(set_ita_size, set_eng_size, embedding_dim, lstm_size, lstm_size, ita_txt_len, max_len_eng, 'concat', att_units, batch_size)\n",
    "model.compile(optimizer = 'Adam', loss = loss_function)\n",
    "log_dir=\"logs/seq2seq/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") call_back = [ModelCheckpoint('ita_eng_4', save_best_only= True),\n",
    "             TensorBoard(log_dir = log_dir, histogram_freq=1, write_graph=True), EarlyStopping(patience = 5, verbose = 1),\n",
    "             ReduceLROnPlateau(patience = 3, verbose = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NQEQFexaFvss",
    "outputId": "4612e3ea-8dc4-4046-a54a-f59f8ff50b4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "1265/1265 [==============================] - 319s 212ms/step - loss: 0.4966 - val_loss: 0.3452\n",
      "Epoch 2/35\n",
      "1265/1265 [==============================] - 248s 196ms/step - loss: 0.3225 - val_loss: 0.2693\n",
      "Epoch 3/35\n",
      "1265/1265 [==============================] - 247s 195ms/step - loss: 0.2524 - val_loss: 0.2244\n",
      "Epoch 4/35\n",
      "1265/1265 [==============================] - 243s 192ms/step - loss: 0.2067 - val_loss: 0.1907\n",
      "Epoch 5/35\n",
      "1265/1265 [==============================] - 243s 192ms/step - loss: 0.1704 - val_loss: 0.1637\n",
      "Epoch 6/35\n",
      "1265/1265 [==============================] - 240s 190ms/step - loss: 0.1383 - val_loss: 0.1394\n",
      "Epoch 7/35\n",
      "1265/1265 [==============================] - 238s 188ms/step - loss: 0.1107 - val_loss: 0.1197\n",
      "Epoch 8/35\n",
      "1265/1265 [==============================] - 239s 189ms/step - loss: 0.0873 - val_loss: 0.1049\n",
      "Epoch 9/35\n",
      "1265/1265 [==============================] - 242s 192ms/step - loss: 0.0689 - val_loss: 0.0935\n",
      "Epoch 10/35\n",
      "1265/1265 [==============================] - 247s 195ms/step - loss: 0.0550 - val_loss: 0.0849\n",
      "Epoch 11/35\n",
      "1265/1265 [==============================] - 244s 193ms/step - loss: 0.0446 - val_loss: 0.0794\n",
      "Epoch 12/35\n",
      "1265/1265 [==============================] - 247s 195ms/step - loss: 0.0368 - val_loss: 0.0747\n",
      "Epoch 13/35\n",
      "1265/1265 [==============================] - 248s 196ms/step - loss: 0.0308 - val_loss: 0.0713\n",
      "Epoch 14/35\n",
      "1265/1265 [==============================] - 246s 195ms/step - loss: 0.0260 - val_loss: 0.0692\n",
      "Epoch 15/35\n",
      "1265/1265 [==============================] - 245s 193ms/step - loss: 0.0225 - val_loss: 0.0685\n",
      "Epoch 16/35\n",
      "1265/1265 [==============================] - 247s 195ms/step - loss: 0.0200 - val_loss: 0.0666\n",
      "Epoch 17/35\n",
      "1265/1265 [==============================] - 247s 195ms/step - loss: 0.0174 - val_loss: 0.0656\n",
      "Epoch 18/35\n",
      "1265/1265 [==============================] - 246s 194ms/step - loss: 0.0156 - val_loss: 0.0645\n",
      "Epoch 19/35\n",
      "1265/1265 [==============================] - 247s 195ms/step - loss: 0.0141 - val_loss: 0.0652\n",
      "Epoch 20/35\n",
      "1265/1265 [==============================] - 246s 194ms/step - loss: 0.0131 - val_loss: 0.0638\n",
      "Epoch 21/35\n",
      "1265/1265 [==============================] - 246s 195ms/step - loss: 0.0121 - val_loss: 0.0649\n",
      "Epoch 22/35\n",
      "1265/1265 [==============================] - 248s 196ms/step - loss: 0.0110 - val_loss: 0.0648\n",
      "Epoch 23/35\n",
      "1265/1265 [==============================] - 246s 195ms/step - loss: 0.0104 - val_loss: 0.0641\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 24/35\n",
      "1265/1265 [==============================] - 245s 194ms/step - loss: 0.0083 - val_loss: 0.0622\n",
      "Epoch 25/35\n",
      "1265/1265 [==============================] - 248s 196ms/step - loss: 0.0069 - val_loss: 0.0620\n",
      "Epoch 26/35\n",
      "1265/1265 [==============================] - 247s 195ms/step - loss: 0.0064 - val_loss: 0.0623\n",
      "Epoch 27/35\n",
      "1265/1265 [==============================] - 248s 196ms/step - loss: 0.0062 - val_loss: 0.0622\n",
      "Epoch 28/35\n",
      "1265/1265 [==============================] - 247s 195ms/step - loss: 0.0060 - val_loss: 0.0627\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 29/35\n",
      "1265/1265 [==============================] - 247s 195ms/step - loss: 0.0057 - val_loss: 0.0626\n",
      "Epoch 30/35\n",
      "1265/1265 [==============================] - 247s 195ms/step - loss: 0.0057 - val_loss: 0.0626\n",
      "Epoch 00030: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcda3e93438>"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = train_dataloader, steps_per_epoch = train_dataloader.__len__(), validation_data = val_dataloader,\n",
    "          validation_steps = val_dataloader.__len__(), epochs = 35, verbose = 1, callbacks = call_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PXbG13IqFvss",
    "outputId": "871925d0-cc7c-48a5-a0c1-a782ee9a7f58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcd49ac8c18>"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = pred_Encoder_decoder(set_ita_size, set_eng_size, embedding_dim, lstm_size, lstm_size, ita_txt_len, max_len_eng, 'concat', att_units)\n",
    "final_output.compile(optimizer = 'Adam', loss = loss_function)\n",
    "final_output.load_weights('/content/ita_eng_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "id": "5d6VzvOaFvss",
    "outputId": "ce6def87-c8ce-49ca-8606-ee61af5abdc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :  ha appena chiamato qualcuno\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output :  somebody just called\n"
     ]
    }
   ],
   "source": [
    "pr_final = train['italin'].values[0][6:-6]\n",
    "print('input : ', pr_final)\n",
    "result = predict(pr_final)\n",
    "print('predicted output : ',result)\n",
    "print('actual output :', train['english'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 774
    },
    "id": "erPMz10FFvss",
    "outputId": "fa2c2bac-a8ab-40e8-e3aa-1616b0f5be79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :  io ero gelosa di voi\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output :  i was jealous of you\n"
     ]
    }
   ],
   "source": [
    "pr_final = train['italin'].values[1000][6:-6]\n",
    "print('input : ', pr_final)\n",
    "result = predict(pr_final)\n",
    "print('predicted output : ',result)\n",
    "print('actual output :', train['english'].values[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ZlvgxKYFvst",
    "outputId": "141a34ca-76d2-4cb4-990a-9a03d9b93549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu Score : 0.8438060676707472\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "initial =0\n",
    "for i in range(1000):\n",
    "    pr_final = test['italin'].values[i][6:-6]\n",
    "    con = test['english'].values[i]\n",
    "    pred = predict(pr_final)\n",
    "    initial+= sentence_bleu([con.split()], pred.split())\n",
    "print('Bleu Score : {}'.format(score/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVPZt7KpFvst"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hleIm2otFvst"
   },
   "source": [
    "* Bleu Score for model-1 is 0.8391122289889017\n",
    "* Bleu Score for model-2 is 0.8262435337297614 (Attention mechanisum)\n",
    "* Bleu Score for model-3 is 0.8442320971046736 (General scoring function)\n",
    "* Bleu Score for model-4 is 0.8438060676707472 (Concat scoring function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Sequence to sequence implementation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
